#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¿èŒ²æµ·é»˜ç—‡åˆ†æè³‡æ–™åº« - Web æœå‹™å™¨
"""

import os
import re
import json
import hashlib
import requests
from datetime import datetime
from pathlib import Path

from flask import Flask, render_template, request, jsonify, send_from_directory
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# é…ç½®
DATASET_PATH = "data/alzheimers_cohort_v1"
DATASET_FILE = "113.csv"  # ä½¿ç”¨ 113.csv æª”æ¡ˆ
ARTIFACT_DIR = "artifacts"
CLAUDE_SERVER_URL = "http://localhost:3000"

app = Flask(__name__)

class WebClaudeService:
    """Web ç‰ˆæœ¬çš„ Claude æœå‹™"""
    
    def __init__(self):
        self.server_url = CLAUDE_SERVER_URL
        self.jobs = {}
    
    def _append_log(self, job_id, message):
        job = self.jobs.get(job_id)
        if job is None:
            return
        logs = job.setdefault('logs', [])
        timestamp = datetime.now().strftime('%H:%M:%S')
        line = "[{}] {}".format(timestamp, message)
        logs.append(line)
        # åŒæ­¥è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿ
        print("[job {}] {}".format(job_id, line))

    def _slugify(self, text, default='artifact'):
        if not text:
            return default
        # keep CJK and alnum, replace others with underscore, then trim
        text = re.sub(r"[^\w\u4e00-\u9fff]+", "_", text)
        text = re.sub(r"_+", "_", text).strip("_")
        return (text or default)[:64]
    
    def generate_code(self, question, outputs, privacy_level):
        """ç”Ÿæˆ Python ç¨‹å¼ç¢¼"""
        
        try:
            # æ§‹å»ºè«‹æ±‚è¨Šæ¯
            message = """
è«‹ç‚ºä»¥ä¸‹é˜¿èŒ²æµ·é»˜ç—‡è³‡æ–™åˆ†æå•é¡Œç”Ÿæˆ Python ç¨‹å¼ç¢¼ï¼š

å•é¡Œï¼š{}
éš±ç§ç­‰ç´šï¼š{}
æœŸæœ›è¼¸å‡ºï¼š{}

è¦æ±‚ï¼š
1. è®€å– CSV æª”æ¡ˆï¼š{}/{}
2. ç”Ÿæˆ {} è¼¸å‡º
3. æ‡‰ç”¨ {} éš±ç§ä¿è­·
4. ä½¿ç”¨ pandas, matplotlib ç­‰åº«
5. å°‡åœ–è¡¨ä¿å­˜åˆ° {}/ ç›®éŒ„
6. è¿”å›å¯åŸ·è¡Œçš„ Python ç¨‹å¼ç¢¼

è³‡æ–™æª”æ¡ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
- ç·¨è™Ÿ, å€‹æ¡ˆç·¨è™Ÿ, å€‹æ¡ˆå§“å, æ€§åˆ¥, èº«åˆ†è­‰å­—è™Ÿ, ç—…æ­·è™Ÿ
- ç”Ÿæ—¥/å¹´é½¡, æ”¶æ¡ˆæ—¥æœŸ, å¤±æ™ºç¨‹åº¦, 0.5ç¨‹åº¦åˆ†ç´š
- å¤±æ™ºç—‡è¨ºæ–·, æœ‰ç„¡ç²¾ç¥è¡Œç‚ºç—‡ç‹€è¨ºæ–·ç¢¼, ä¸»æ²»é†«å¸«
- å¤±æ™ºè¨ºæ–·æƒ…æ³è² è²¬é†«å¸«, å‚™è¨», NCVæª¢æŸ¥, APOE

è¼¸å‡ºæ ¼å¼è¦æ±‚ï¼ˆé‡è¦ï¼‰ï¼š
- åªè¼¸å‡ºç´” Python ç¨‹å¼ç¢¼ï¼Œä¸”ä¸è¦åŒ…å« Markdownã€ä¸è¦åŒ…å«```æ¨™è¨˜ã€ä¸è¦ä»»ä½•è§£èªªæ–‡å­—ã€‚
- ç¨‹å¼ç¢¼ä¸­ç›´æ¥ä½¿ç”¨è®Šæ•¸ ARTIFACT_DIR ä½œç‚ºè¼¸å‡ºç›®éŒ„ã€‚
            """.format(question, privacy_level, ', '.join(outputs), DATASET_PATH, DATASET_FILE, ', '.join(outputs), privacy_level, ARTIFACT_DIR).strip()
            
            # ç™¼é€è«‹æ±‚åˆ° Claude Code Server
            response = requests.post(
                "{}/api/execute".format(self.server_url),
                headers={"Content-Type": "application/json"},
                json={
                    "message": message,
                    "timeout": 30000
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                # å…¼å®¹ä¸åŒæ¬„ä½åï¼ˆéƒ¨åˆ†æœå‹™å›å‚³ outputï¼‰
                code = result.get('result') or result.get('output') or ''
                # å»é™¤å¯èƒ½çš„ Markdown ç¨‹å¼ç¢¼åœæ¬„
                if isinstance(code, str):
                    stripped = code.strip()
                    if stripped.startswith('```'):
                        # å»é™¤é–‹é ­çš„```èªæ³•èˆ‡å¯é¸èªè¨€æ¨™ç±¤
                        stripped = stripped.lstrip('`')
                        # å†æ¬¡ä¿å®ˆè™•ç†ï¼šç§»é™¤å¯èƒ½çš„é–‹é ­ 'python' æ›è¡Œ
                        if '\n' in stripped:
                            stripped = stripped.split('\n', 1)[1]
                        # å»é™¤çµå°¾çš„```
                        stripped = stripped.rstrip('`').strip()
                    code = stripped
                
                # ç”Ÿæˆç¨‹å¼ç¢¼é›œæ¹Š
                code_hash = hashlib.sha256(code.encode()).hexdigest()
                
                return {
                    'code': code,
                    'code_hash': code_hash,
                    'question': question,
                    'outputs': outputs,
                    'privacy_level': privacy_level,
                    'source': 'claude_code_server'
                }
            else:
                raise Exception("Claude Code Server å›æ‡‰éŒ¯èª¤: {}".format(response.status_code))
                
        except Exception as e:
            print("Claude Code Server èª¿ç”¨å¤±æ•—: {}".format(e))
            # è¿”å›é è¨­ç¨‹å¼ç¢¼
            return self._generate_default_code(question, outputs, privacy_level)
    
    def _generate_default_code(self, question, outputs, privacy_level):
        """ç”Ÿæˆé è¨­ç¨‹å¼ç¢¼"""
        
        code = '''# ç”Ÿæˆç¨‹å¼ç¢¼: {}
# éš±ç§ç­‰ç´š: {}
# è¼¸å‡ºé¡å‹: {}

import pandas as pd
import matplotlib.pyplot as plt

# è®€å– CSV è³‡æ–™
df = pd.read_csv('{}/{}')

# åŸºæœ¬çµ±è¨ˆ
        print("è³‡æ–™é›†å¤§å°: {}".format(df.shape))
        print("æ¬„ä½: {}".format(list(df.columns)))

# ç”Ÿæˆè¼¸å‡º
'''.format(question, privacy_level, ', '.join(outputs), DATASET_PATH, DATASET_FILE)
        
        if "plot" in outputs:
            code += '''
# è³‡æ–™å‰è™•ç†ï¼šæ¬„ä½çµ±ä¸€èˆ‡å¹´é½¡æ¬„ä½è¾¨è­˜
df.columns = [str(c).replace(' ', '') for c in df.columns]
age_candidates = ['ç”Ÿæ—¥/å¹´é½¡', 'ç”Ÿæ—¥/å¹´é½¡', 'ç”Ÿæ—¥/å¹´é½¡', 'ç”Ÿæ—¥/å¹´é½¡', 'ç”Ÿæ—¥/å¹´é½¡']
age_candidates = list(dict.fromkeys(age_candidates + ['ç”Ÿæ—¥/å¹´é½¡','ç”Ÿæ—¥/å¹´é½¡','å¹´é½¡']))
age_col = None
for c in df.columns:
    if 'å¹´é½¡' in c:
        age_col = c
        break
if age_col is None:
    age_col = 'ç”Ÿæ—¥/å¹´é½¡' if 'ç”Ÿæ—¥/å¹´é½¡' in df.columns else df.columns[0]

# å¹´é½¡è½‰æ•¸å€¼ä¸¦æ¸…ç†
age_series = pd.to_numeric(df[age_col], errors='coerce').dropna()
age_series = age_series[(age_series > 0) & (age_series < 120)]

# ç•«å‡ºå¹´é½¡åˆ†å¸ƒåœ–ï¼ˆç›´æ–¹åœ–ï¼‰
plt.figure(figsize=(10, 6))
age_series.hist(bins=20, alpha=0.8, color='steelblue', edgecolor='white')
plt.title('ç—…æ‚£å¹´é½¡åˆ†å¸ƒ')
plt.xlabel('å¹´é½¡')
plt.ylabel('äººæ•¸')
plt.tight_layout()
outfile = "{}/{}_{}_plot.png".format(ARTIFACT_DIR, ARTIFACT_BASENAME, job_id)
plt.savefig(outfile, dpi=300, bbox_inches='tight')
plt.close()
'''
        
        if "table" in outputs:
            code += '''
# ç”Ÿæˆå¹´é½¡çµ±è¨ˆè¡¨æ ¼
age_stats = age_series.describe().to_frame(name='age')

# ä¾å€é–“çµ±è¨ˆåˆ†å¸ƒ
bins = [0, 50, 60, 70, 80, 90, 120]
labels = ['<50','50-59','60-69','70-79','80-89','90+']
age_bins = pd.cut(age_series, bins=bins, labels=labels, right=False)
age_bin_counts = age_bins.value_counts().sort_index().to_frame(name='count')

summary = pd.concat([age_stats, age_bin_counts], axis=1)
summary.to_csv("{}/{}_{}_summary.csv".format(ARTIFACT_DIR, ARTIFACT_BASENAME, job_id))
'''
        
        if "explanation" in outputs:
            code += '''
# ç”Ÿæˆåˆ†æèªªæ˜
explanation = "è³‡æ–™é›†åŒ…å« {} ç­†è¨˜éŒ„ï¼Œ{} å€‹æ¬„ä½ã€‚".format(len(df), len(df.columns))
with open('{}/explanation.txt'.format(ARTIFACT_DIR), 'w', encoding='utf-8') as f:
    f.write(explanation)
'''
        
        code_hash = hashlib.sha256(code.encode()).hexdigest()
        
        return {
            'code': code,
            'code_hash': code_hash,
            'question': question,
            'outputs': outputs,
            'privacy_level': privacy_level,
            'source': 'default'
        }
    
    def execute_code(self, code, job_id):
        """åŸ·è¡Œ Python ç¨‹å¼ç¢¼"""
        
        try:
            # å‰µå»º artifacts ç›®éŒ„
            artifacts_dir = Path(ARTIFACT_DIR) / job_id
            artifacts_dir.mkdir(parents=True, exist_ok=True)
            
            # è¨­ç½®ç’°å¢ƒè®Šæ•¸
            os.environ['ARTIFACT_DIR'] = str(artifacts_dir)
            
            # åŸ·è¡Œç¨‹å¼ç¢¼
            exec_globals = {
                '__builtins__': __builtins__,
                '__name__': '__main__',
                '__file__': 'analysis_{}.py'.format(job_id),
                'ARTIFACT_DIR': str(artifacts_dir)  # æ·»åŠ  ARTIFACT_DIR è®Šæ•¸
            }
            
            # æ·»åŠ å¿…è¦çš„æ¨¡çµ„
            try:
                import pandas as pd
                import matplotlib
                matplotlib.use('Agg')  # ä½¿ç”¨éäº’å‹•å¼å¾Œç«¯
                import matplotlib.pyplot as plt
                # è¨­å®šå¯é¡¯ç¤ºä¸­æ–‡çš„å­—å‹ï¼ˆmacOS å„ªå…ˆ PingFangï¼Œå…¶æ¬¡ Noto/Arial Unicodeï¼‰
                try:
                    matplotlib.rcParams['font.sans-serif'] = [
                        'PingFang TC', 'PingFang HK', 'PingFang SC',
                        'Noto Sans CJK TC', 'Noto Sans CJK SC', 'Noto Sans CJK JP',
                        'Heiti TC', 'Hiragino Sans GB', 'Arial Unicode MS', 'Songti SC', 'STHeiti'
                    ]
                    matplotlib.rcParams['axes.unicode_minus'] = False
                except Exception:
                    pass
                import numpy as np
                # å°‡ä»»å‹™æ¨™é¡Œæä¾›çµ¦ä»£ç¢¼ä½¿ç”¨ï¼ˆå¯è‡ªè¨‚è¼¸å‡ºæª”åï¼‰
                job_meta = self.jobs.get(job_id, {})
                artifact_basename = job_meta.get('artifact_basename', 'artifact')
                exec_globals.update({
                    'pd': pd,
                    'plt': plt,
                    'np': np,
                    'df': None,  # å°‡åœ¨ç¨‹å¼ç¢¼ä¸­è¨­ç½®
                    'ARTIFACT_BASENAME': artifact_basename
                })
            except ImportError as e:
                return {'status': 'error', 'error': 'æ¨¡çµ„å°å…¥å¤±æ•—: {}'.format(e)}
            
            # åŸ·è¡Œç¨‹å¼ç¢¼
            exec(code, exec_globals)
            
            # æª¢æŸ¥ç”Ÿæˆçš„æª”æ¡ˆ
            artifacts = []
            if artifacts_dir.exists():
                for file_path in artifacts_dir.iterdir():
                    if file_path.is_file():
                        artifacts.append(file_path.name)
            
            return {
                'status': 'success',
                'artifacts': artifacts,
                'message': 'ç¨‹å¼ç¢¼åŸ·è¡ŒæˆåŠŸ'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'artifacts': []
            }
    
    def create_analysis(self, question, outputs, privacy_level):
        """å‰µå»ºåˆ†æå·¥ä½œ"""
        
        job_id = "job_{}_{}".format(len(self.jobs) + 1, int(datetime.now().timestamp()))
        # åˆå§‹åŒ–å·¥ä½œï¼ˆå…ˆå¯«å…¥ï¼Œä»¥ä¾¿å³æ™‚è¿½åŠ æ—¥èªŒï¼‰
        artifact_basename = self._slugify(question)
        self.jobs[job_id] = {
            'question': question,
            'outputs': outputs,
            'privacy_level': privacy_level,
            'code_hash': '',
            'execution_result': {'status': 'processing', 'artifacts': []},
            'created_at': datetime.now().isoformat(),
            'code': '',
            'logs': [],
            'artifact_basename': artifact_basename
        }
        
        self._append_log(job_id, 'æ”¶åˆ°åˆ†æè«‹æ±‚')
        self._append_log(job_id, 'æ­£åœ¨å‘¼å« Claude Code Server ç”¢ç”Ÿç¨‹å¼ç¢¼')
        
        # ç”Ÿæˆç¨‹å¼ç¢¼
        code_result = self.generate_code(question, outputs, privacy_level)
        self.jobs[job_id]['code'] = code_result['code']
        self.jobs[job_id]['code_hash'] = code_result['code_hash']
        self._append_log(job_id, "ç¨‹å¼ç¢¼ä¾†æº: {}".format(code_result.get('source', 'unknown')))
        
        # åŸ·è¡Œç¨‹å¼ç¢¼
        self._append_log(job_id, 'é–‹å§‹åŸ·è¡Œåˆ†æç¨‹å¼ç¢¼')
        execution_result = self.execute_code(code_result['code'], job_id)
        self.jobs[job_id]['execution_result'] = execution_result
        
        if execution_result.get('status') == 'success':
            artifacts = execution_result.get('artifacts', [])
            self._append_log(job_id, "åˆ†æå®Œæˆï¼Œç”¢å‡ºæª”æ¡ˆ: {}".format(', '.join(artifacts) if artifacts else 'ç„¡'))
        else:
            self._append_log(job_id, "åˆ†æå¤±æ•—: {}".format(execution_result.get('error', 'æœªçŸ¥éŒ¯èª¤')))
        
        return job_id
    
    def get_job_status(self, job_id):
        """ç²å–å·¥ä½œç‹€æ…‹"""
        return self.jobs.get(job_id, {'error': 'å·¥ä½œä¸å­˜åœ¨'})
    
    def list_jobs(self):
        """åˆ—å‡ºæ‰€æœ‰å·¥ä½œ"""
        return [
            {
                'job_id': job_id,
                'question': job_info['question'],
                'status': 'completed',
                'created_at': job_info['created_at'],
                'artifacts': job_info['execution_result'].get('artifacts', [])
            }
            for job_id, job_info in self.jobs.items()
        ]

# å‰µå»ºæœå‹™å¯¦ä¾‹
claude_service = WebClaudeService()

@app.route('/')
def index():
    """ä¸»é é¢"""
    return render_template('index.html')

@app.route('/api/analyze', methods=['POST'])
def analyze():
    """åˆ†æ API ç«¯é»"""
    try:
        data = request.get_json()
        question = data.get('question', '')
        outputs = data.get('outputs', ['plot', 'table'])
        privacy_level = data.get('privacy_level', 'k_anonymous')
        
        if not question:
            return jsonify({'error': 'å•é¡Œä¸èƒ½ç‚ºç©º'}), 400
        
        # å‰µå»ºåˆ†æå·¥ä½œ
        job_id = claude_service.create_analysis(question, outputs, privacy_level)
        
        return jsonify({
            'job_id': job_id,
            'message': 'åˆ†æå·¥ä½œå·²å‰µå»º',
            'status': 'success'
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/job/<job_id>')
def get_job(job_id):
    """ç²å–å·¥ä½œç‹€æ…‹"""
    job_status = claude_service.get_job_status(job_id)
    # è‹¥å·¥ä½œå­˜åœ¨ï¼Œè£œä¸Š job_id æ–¹ä¾¿å‰ç«¯çµ„è£æª”æ¡ˆé€£çµ
    if 'error' not in job_status:
        job_status_with_id = { 'job_id': job_id, **job_status }
        return jsonify(job_status_with_id)
    return jsonify(job_status)

@app.route('/api/jobs')
def list_jobs():
    """åˆ—å‡ºæ‰€æœ‰å·¥ä½œ"""
    jobs = claude_service.list_jobs()
    return jsonify(jobs)

@app.route('/files/<job_id>/<filename>')
def get_file(job_id, filename):
    """ç²å–ç”Ÿæˆçš„æ–‡ä»¶"""
    file_path = Path(ARTIFACT_DIR) / job_id / filename
    if file_path.exists():
        return send_from_directory(Path(ARTIFACT_DIR) / job_id, filename)
    else:
        return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404

@app.route('/health')
def health():
    """å¥åº·æª¢æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'claude_server': 'http://localhost:3000'
    })

@app.route('/download/<filename>')
def download_file(filename):
    """ä¸‹è¼‰æª”æ¡ˆ"""
    try:
        # åªå…è¨±ä¸‹è¼‰å»è­˜åˆ¥åŒ–çš„ CSV æª”æ¡ˆ
        if filename == 'anonymized_csv.zip':
            file_path = Path('static/downloads') / filename
            if file_path.exists():
                return send_from_directory('static/downloads', filename, as_attachment=True)
            else:
                return jsonify({'error': 'æª”æ¡ˆä¸å­˜åœ¨'}), 404
        else:
            return jsonify({'error': 'ä¸å…è¨±ä¸‹è¼‰æ­¤æª”æ¡ˆ'}), 403
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/download-info')
def get_download_info():
    """ç²å–ä¸‹è¼‰è³‡è¨Š"""
    try:
        info_path = Path('static/downloads/download_info.json')
        if info_path.exists():
            with open(info_path, 'r', encoding='utf-8') as f:
                info = json.load(f)
            return jsonify(info)
        else:
            return jsonify({'error': 'ä¸‹è¼‰è³‡è¨Šä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/about')
def about():
    """é—œæ–¼é é¢"""
    return render_template('about.html')

@app.route('/database/<database_name>')
def database_detail(database_name):
    """è³‡æ–™åº«è©³æƒ…é é¢"""
    if database_name == 'dementia':
        database = {
            'title': 'è‡ºç£å¤±æ™ºç—‡è‡¨åºŠè³‡æ–™åº«',
            'authors': 'è‡ºåŒ—é†«å­¸å¤§å­¸é›™å’Œé†«é™¢å¤±æ™ºç—‡ä¸­å¿ƒèˆ‡ç¥ç¶“å…§ç§‘ç ”ç©¶åœ˜éšŠ',
            'publication_date': '2025å¹´8æœˆ28æ—¥',
            'version': '1.0.0',
            'abstract': 'é€™é …ç ”ç©¶æ¡ç”¨è‡ºåŒ—é†«å­¸å¤§å­¸é›™å’Œé†«é™¢å¤±æ™ºç—‡ä¸­å¿ƒèˆ‡ç¥ç¶“å…§ç§‘çš„å—è©¦è€…è³‡æ–™ï¼Œå»ºç«‹äº†ä»¥é˜¿èŒ²æµ·é»˜ç—‡æ‚£è€…ç‚ºæ ¸å¿ƒçš„è‡¨åºŠè³‡æ–™åº«ã€‚è©²è³‡æ–™åº«æ”¶éŒ„ç¬¦åˆç¾åœ‹åœ‹å®¶è€åŒ–ç ”ç©¶é™¢-é˜¿èŒ²æµ·é»˜ç—‡å”æœƒ(NIA-AA)æ¨™æº–çš„ç–‘ä¼¼ADæ‚£è€…ï¼Œæ”¶é›†çš„å…§å®¹åŒ…å«ç—…æ­·ã€ç¥ç¶“å¿ƒç†è©•ä¼°ï¼ˆå¦‚MMSEã€CASIã€CDRï¼‰ã€æŒçºŒå¤šå¹´çš„è¿½è¹¤æ•¸æ“šåŠéƒ¨åˆ†æ‚£è€…çš„è…¦éƒ¨MRIå½±åƒã€‚æ‰€æœ‰æ•¸æ“šç¶“éåš´æ ¼å»è­˜åˆ¥åŒ–è™•ç†ï¼Œä¸¦éµç…§ç ”ç©¶å€«ç†è¦ç¯„ï¼ŒåŒ…å«äººå£çµ±è¨ˆã€ç—…ç¨‹ã€æ•™è‚²å¹´æ•¸ã€ç¥ç¶“å¿ƒç†å¤šé ˜åŸŸæ¸¬é©—åˆ†æ•¸ã€è‡¨åºŠå¤±æ™ºåš´é‡åº¦ã€è…¦èç¸®èˆ‡ç™½è³ªç—…ç¶è©•åˆ†ç­‰è©³ç´°è®Šé …ã€‚',
            'background': 'è©²è³‡æ–™åº«çš„æ‚£è€…æ¶µè“‹è¼•è‡³ä¸­åº¦é˜¿èŒ²æµ·é»˜ç—‡ï¼Œå…·å‚™å¤šæ¬¡å¹´åº¦è©•ä¼°ç´€éŒ„èˆ‡å®Œæ•´éš¨è¨ªè³‡æ–™ã€‚ç ”ç©¶åœ˜éšŠå°‡ç¥ç¶“å¿ƒç†è©•ä¼°å„é¢å‘çµåˆæ©Ÿå™¨å­¸ç¿’æ–¹æ³•é€²è¡Œç•°è³ªæ€§åˆ†é¡ï¼Œä¿ƒé€²äºå‹åˆ†ç¾¤åˆ†æã€‚',
            'methods': 'è³‡æ–™æ”¶é›†æ¡ç”¨æ¨™æº–åŒ–ç¥ç¶“å¿ƒç†è©•ä¼°å·¥å…·ï¼ŒåŒ…æ‹¬MMSEã€CASIã€CDRç­‰é‡è¡¨ã€‚æ‰€æœ‰æ•¸æ“šç¶“éåš´æ ¼å»è­˜åˆ¥åŒ–è™•ç†ï¼Œç¢ºä¿æ‚£è€…éš±ç§ä¿è­·ã€‚',
            'data_description': 'è³‡æ–™åº«åŒ…å«å¤šå€‹CSVæª”æ¡ˆï¼Œæ¶µè“‹æ‚£è€…åŸºæœ¬è³‡è¨Šã€è¨ºæ–·çµæœã€èªçŸ¥æ¸¬è©¦åˆ†æ•¸ã€è…¦éƒ¨å½±åƒè©•åˆ†ç­‰ã€‚',
            'usage_notes': 'æœ¬è³‡æ–™åº«åƒ…ä¾›ç ”ç©¶ä½¿ç”¨ï¼Œä½¿ç”¨è€…éœ€éµå®ˆç›¸é—œå€«ç†è¦ç¯„å’Œè³‡æ–™ä½¿ç”¨å”è­°ã€‚',
            'release_notes': 'åˆå§‹ç‰ˆæœ¬åŒ…å«2012-2024å¹´æ”¶æ¡ˆè³‡æ–™ï¼Œç¶“éå»è­˜åˆ¥åŒ–è™•ç†å¾Œç™¼å¸ƒã€‚',
            'ethics': 'æœ¬ç ”ç©¶å·²é€šéè‡ºåŒ—é†«å­¸å¤§å­¸äººé«”è©¦é©—å§”å“¡æœƒå¯©æŸ¥ï¼Œæ‰€æœ‰åƒèˆ‡è€…å‡ç°½ç½²çŸ¥æƒ…åŒæ„æ›¸ã€‚',
            'acknowledgements': 'æ„Ÿè¬æ‰€æœ‰åƒèˆ‡ç ”ç©¶çš„æ‚£è€…åŠå…¶å®¶å±¬ï¼Œä»¥åŠç ”ç©¶åœ˜éšŠæˆå“¡çš„è²¢ç»ã€‚',
            'conflicts_of_interest': 'ç ”ç©¶åœ˜éšŠè²æ˜ç„¡åˆ©ç›Šè¡çªã€‚',
            'references': [
                'Nguyen TTT, Lee HH, Huang LK, et al. Heterogeneity of Alzheimer\'s disease identified by neuropsychological test profiling. PLoS One. 2023;18(10):e0292527. https://pubmed.ncbi.nlm.nih.gov/37797059/',
                'American Psychiatric Association. Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5). Arlington, VA: American Psychiatric Association, 2013.',
                'McKhann GM, et al. The diagnosis of dementia due to Alzheimer\'s disease: recommendations from the National Institute on Aging-Alzheimer\'s Association workgroups on diagnostic guidelines for Alzheimer\'s disease. Alzheimers Dement. 2011;7(3):263-9.',
                'Folstein MF, Folstein SE, McHugh PR. "Mini-mental state". A practical method for grading the cognitive state of patients for the clinician. J Psychiatr Res. 1975;12(3):189-98.'
            ],
            'access_policy': 'é–‹æ”¾å­˜å–ï¼Œéœ€è¨»å†Šå¸³è™Ÿä¸¦åŒæ„ä½¿ç”¨æ¢æ¬¾ã€‚',
            'license': 'Creative Commons Attribution 4.0 International License',
            'doi': '10.1371/journal.pone.0292527',
            'topics': ['é˜¿èŒ²æµ·é»˜ç—‡', 'ç¥ç¶“å¿ƒç†è©•ä¼°', 'èªçŸ¥åŠŸèƒ½', 'æ©Ÿå™¨å­¸ç¿’', 'ç•°è³ªæ€§åˆ†æ'],
            'project_website': 'https://neurologytmu.loinc100.org',
            'total_size': '213.29 KB',
            'zip_size': '213.29 KB',
            'download_url': '/download/anonymized_csv.zip',
            'wget_command': 'wget http://localhost:5001/download/anonymized_csv.zip',
            'versions': [
                {'number': '1.0.0', 'date': '2025å¹´8æœˆ28æ—¥'}
            ]
        }
        return render_template('database_detail.html', database=database)
    else:
        return jsonify({'error': 'è³‡æ–™åº«ä¸å­˜åœ¨'}), 404

if __name__ == '__main__':
    # æª¢æŸ¥è³‡æ–™æª”æ¡ˆ
    csv_file = Path(DATASET_PATH) / DATASET_FILE
    if not csv_file.exists():
        print("âŒ æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ: {}".format(csv_file))
        print("   è«‹ç¢ºä¿ CSV æª”æ¡ˆå·²æ”¾ç½®åœ¨æ­£ç¢ºä½ç½®")
        exit(1)
    
    print("âœ… æ‰¾åˆ°è³‡æ–™æª”æ¡ˆ: {}".format(csv_file))
    print("ğŸŒ å•Ÿå‹• Web æœå‹™å™¨...")
    print("ğŸ“± è¨ªå•: http://localhost:5001")
    
    app.run(host='0.0.0.0', port=5001, debug=True)
